#!/usr/bin/env python3
"""
BERTæ³•å¾‹æ¨¡å‹è®­ç»ƒå¯åŠ¨è„šæœ¬
"""
import os
import sys
import argparse
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(str(Path(__file__).parent))

from app.services.data_collector import LegalDataCollector
from app.services.model_training import LegalBERTTrainer

def main():
    parser = argparse.ArgumentParser(description='è®­ç»ƒæ³•å¾‹BERTæ¨¡å‹')
    parser.add_argument('--data_path', type=str, default='./data/training/legal_training_data.json',
                       help='è®­ç»ƒæ•°æ®è·¯å¾„')
    parser.add_argument('--output_dir', type=str, default='./models/legal-bert-trained',
                       help='æ¨¡å‹è¾“å‡ºç›®å½•')
    parser.add_argument('--epochs', type=int, default=3,
                       help='è®­ç»ƒè½®æ•°')
    parser.add_argument('--batch_size', type=int, default=16,
                       help='æ‰¹æ¬¡å¤§å°')
    parser.add_argument('--learning_rate', type=float, default=2e-5,
                       help='å­¦ä¹ ç‡')
    parser.add_argument('--max_length', type=int, default=512,
                       help='æœ€å¤§æ–‡æœ¬é•¿åº¦')
    parser.add_argument('--collect_data', action='store_true',
                       help='æ˜¯å¦å…ˆæ”¶é›†æ•°æ®')
    
    args = parser.parse_args()
    
    print("ğŸ¤– æ³•å¾‹BERTæ¨¡å‹è®­ç»ƒ")
    print("=" * 50)
    
    # 1. æ•°æ®æ”¶é›†ï¼ˆå¦‚æœéœ€è¦ï¼‰
    if args.collect_data or not os.path.exists(args.data_path):
        print("ğŸ“š æ­¥éª¤1: æ”¶é›†è®­ç»ƒæ•°æ®")
        collector = LegalDataCollector()
        collector.create_synthetic_data()
        collector.process_data()
        collector.save_data(os.path.basename(args.data_path))
        print()
    
    # 2. æ¨¡å‹è®­ç»ƒ
    print("ğŸš€ æ­¥éª¤2: å¼€å§‹æ¨¡å‹è®­ç»ƒ")
    
    # è®­ç»ƒé…ç½®
    config = {
        'model_name': 'bert-base-chinese',
        'num_labels': 10,
        'max_length': args.max_length,
        'epochs': args.epochs,
        'batch_size': args.batch_size,
        'learning_rate': args.learning_rate,
        'warmup_steps': 500,
        'output_dir': args.output_dir
    }
    
    # åˆ›å»ºè®­ç»ƒå™¨
    trainer = LegalBERTTrainer(config)
    
    # è®¾ç½®æ¨¡å‹
    trainer.setup_model()
    
    # å‡†å¤‡æ•°æ®
    train_dataset, val_dataset = trainer.prepare_data(args.data_path)
    
    # å¼€å§‹è®­ç»ƒ
    trainer.train(train_dataset, val_dataset)
    
    print("\nâœ… è®­ç»ƒå®Œæˆï¼")
    print(f"ğŸ“ æ¨¡å‹ä¿å­˜åœ¨: {args.output_dir}")
    print("\nğŸ§ª æµ‹è¯•æ¨¡å‹:")
    
    # æµ‹è¯•é¢„æµ‹
    test_cases = [
        "åˆåŒåŒæ–¹åº”å½“æŒ‰ç…§çº¦å®šå±¥è¡Œä¹‰åŠ¡",
        "ç”¨äººå•ä½åº”å½“ä¸ºåŠ³åŠ¨è€…ç¼´çº³ç¤¾ä¼šä¿é™©",
        "ä¾µçŠ¯ä»–äººçŸ¥è¯†äº§æƒåº”å½“æ‰¿æ‹…æ³•å¾‹è´£ä»»"
    ]
    
    for text in test_cases:
        try:
            result = trainer.predict(text)
            print(f"æ–‡æœ¬: {text}")
            print(f"é¢„æµ‹ç±»åˆ«: {result['predicted_class']}")
            print(f"ç½®ä¿¡åº¦: {result['confidence']:.4f}")
            print("-" * 50)
        except Exception as e:
            print(f"é¢„æµ‹å¤±è´¥: {e}")

if __name__ == "__main__":
    main()






